<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>Plate2Recipe</title>
  <meta content="" name="description">
  <meta content="" name="keywords">

  <!-- Favicons -->
  <link href="../assets/img/favicon.png" rel="icon">
  <link href="../assets/img/apple-touch-icon.png" rel="apple-touch-icon">

  <!-- Google Fonts -->
  <link
    href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Raleway:300,300i,400,400i,500,500i,600,600i,700,700i|Poppins:300,300i,400,400i,500,500i,600,600i,700,700i"
    rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="../assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="../assets/vendor/icofont/icofont.min.css" rel="stylesheet">
  <link href="../assets/vendor/remixicon/remixicon.css" rel="stylesheet">
  <link href="../assets/vendor/owl.carousel/assets/owl.carousel.min.css" rel="stylesheet">
  <link href="../assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
  <link href="../assets/vendor/venobox/venobox.css" rel="stylesheet">

  <!-- Template Main CSS File -->
  <link href="../assets/css/style.css" rel="stylesheet">

  <!-- =======================================================
  * Template Name: Personal - v2.2.0
  * Template URL: https://bootstrapmade.com/personal-free-resume-bootstrap-template/
  * Author: BootstrapMade.com
  * License: https://bootstrapmade.com/license/
  ======================================================== -->
</head>

<body data-gr-c-s-loaded="true">

  <!-- ======= Portfolio Details ======= -->
  <main id="main">
    <div id="portfolio-details" class="portfolio-details">
      <div class="container">

        <div class="row">

          <div class="col-lg-12 portfolio-info">            
            <br>
            <h2>Plate2Recipe – Food Image to Recipe Generation</h2>
            <p><em>Multimodal two-stage pipeline: food image → ingredients → structured recipe generation.</em></p>
            
            <p>
              <a href="https://github.com/cordovank/Plate2Recipe" target="_blank" rel="noopener">GitHub</a>
              <span> · </span>
              <a href="../assets/docs/reports/P2R_Report.pdf" target="_blank" rel="noopener">Report (PDF)</a>
              <span> · </span>
              <a href="../index.html#portfolio">Back to Projects</a>
            </p>
            
            <hr>
            <p><strong>Stack:</strong> PyTorch · Hugging Face Datasets/Transformers · ViT · GPT-2 · TensorFlow (LSTM baseline)</p>
            
            <hr>

            <ul>
              <li><strong>Problem:</strong> Generate structured recipes from a single food image (ingredients + instructions).</li>
              <li><strong>Approach:</strong> ViT-based ingredient recognition + recipe text generation (GPT-2 / LSTM) conditioned on ingredients.</li>
              <li><strong>Outcome:</strong> Produced coherent, structured recipes; documented practical limits around robustness and scalability.</li>
            </ul>
            <hr>

            <p>
              This project aims to create an end-to-end system that converts food images into structured recipes,
              combining computer vision and natural language processing techniques.
            </p>
            <ul>
              <li><strong>Two-stage multimodal pipeline:</strong> food image → ingredient/food label prediction (ViT) → recipe text generation (GPT-2 / LSTM).</li>

              <li><strong>Vision (Food-101 fine-tuning):</strong> fine-tuned <code>google/vit-base-patch16-224-in21k</code> on Food-101
                (224×224 inputs, augmentation like cropping/flips/rotations; trained on a T4 GPU in Colab).</li>

              <li><strong>Ingredient extraction (Recipe1M+):</strong> trained an ingredient extractor using ViT feature embeddings and a decoder inspired by FIRE (Chhikara et al., 2023),
                with preprocessing to remove unreadable/empty images.</li>

              <li><strong>Recipe generation (RecipeNLG):</strong> fine-tuned GPT-2 Medium using a structured prompt format (ingredients → title/ingredients/directions).
                Compared training on 100k vs 10k samples due to compute constraints.</li>

              <li><strong>Iteration learnings:</strong> lower training loss on 100k did not imply better outputs (poor generations);
                after adjusting setup and using 10k samples, outputs became more coherent and ingredient-consistent.</li>
            </ul>

            <hr>
            <h4>Results & Failure Modes</h4>
            <ul>
              <li><strong>ViT fine-tuning:</strong> training/eval loss decreased and eval accuracy increased during Food-101 fine-tuning (reported learning curves).</li>
              <li><strong>GPT-2 generation:</strong> pretrained GPT-2 produced irrelevant/hallucinated recipe text; early fine-tuning attempts produced nonsensical outputs.</li>
              <li><strong>10k vs 100k GPT-2 runs:</strong> the 10k run produced more coherent step-by-step instructions and better ingredient adherence, while the 100k run often degraded despite lower training loss.</li>
              <li><strong>LSTM baseline:</strong> character-level LSTM showed signs of overfitting and produced unstable outputs; early stopping was identified as a likely improvement.</li>
            </ul>

            <hr>
            <h4>Engineering Notes</h4>
            <ul>
              <li><strong>Dataset handling:</strong> used Hugging Face Datasets for efficient loading and preprocessing; relied on streaming/iterating patterns to manage large corpora.</li>
              <li><strong>Image preprocessing:</strong> standardized inputs to <code>224×224</code>, normalized RGB channels, and applied augmentation to improve robustness.</li>
              <li><strong>Prompt formatting matters:</strong> GPT-2 training required structured recipe formatting (title/ingredients/directions) and length control to fit model limits.</li>
              <li><strong>Quality ≠ loss:</strong> the 100k-sample GPT-2 run produced poor text despite lower training loss; the smaller 10k run produced more coherent, usable outputs after adjustments.</li>
              <li><strong>Pipeline brittleness:</strong> ingredient prediction errors propagate directly into generation quality—making the vision stage a major bottleneck for end-to-end performance.</li>
            </ul>

            <hr>
            <h4>What I'd Improve Next</h4>
            <ul>
              <li><strong>Evaluation harness:</strong> add quantitative checks for ingredient precision/recall and recipe consistency (ingredient coverage in generated steps).</li>
              <li><strong>Constrained generation:</strong> enforce ingredient grounding (e.g., post-check that generated recipes don’t introduce unseen ingredients).</li>
              <li><strong>Better conditioning:</strong> move from plain ingredient prompts to structured slots (title → ingredients → steps) with stronger formatting constraints.</li>
              <li><strong>Robustness:</strong> test across image quality, occlusion, and multi-dish scenes; improve ingredient extractor with calibration and thresholding.</li>
            </ul>

          </div>



        </div>

      </div>
    </div><!-- End Portfolio Details -->
  </main><!-- End #main -->

  <!-- Vendor JS Files -->
  <script async="" src="//www.google-analytics.com/analytics.js"></script>
  <script src="assets/vendor/jquery/jquery.min.js"></script>
  <script src="../assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="../assets/vendor/jquery.easing/jquery.easing.min.js"></script>
  <script src="../assets/vendor/php-email-form/validate.js"></script>
  <script src="../assets/vendor/waypoints/jquery.waypoints.min.js"></script>
  <script src="../assets/vendor/counterup/counterup.min.js"></script>
  <script src="../assets/vendor/owl.carousel/owl.carousel.min.js"></script>
  <script src="../assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="../assets/vendor/venobox/venobox.min.js"></script>

  <!-- Template Main JS File -->
  <script src="../assets/js/main.js"></script>

  <script>if (window.self == window.top) { (function (i, s, o, g, r, a, m) { i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () { (i[r].q = i[r].q || []).push(arguments) }, i[r].l = 1 * new Date(); a = s.createElement(o), m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m) })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga'); ga('create', 'UA-55234356-4', 'auto'); ga('send', 'pageview'); } </script>

</body>

</html>